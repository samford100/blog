webpackJsonp([60523007345971],{324:function(t,n){t.exports={data:{markdownRemark:{html:"<p>Reddit is a content aggregation site where users submit pictures, and links, and videos, and just about anything else. Inside reddit, there are places called subreddits, which set the topic of discussion and content. Each NBA team has their own subreddit, and fans, or anyone, but mostly fans, can post content relating to their team. Here's a look at the top posts of the day for the Boston Celtics subreddit, <a href=\"reddit.com/r/bostonceltics\">reddit.com/r/bostonceltics</a>.</p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/celtics-a8b4b26290bb67fa2396fc6d3ae9d0cc-79e2c.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 55.52367288378767%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAIFAwb/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABrsuyc6XyP//EABkQAAMAAwAAAAAAAAAAAAAAAAABAgMQMv/aAAgBAQABBQJFcTgsjSP/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAZEAABBQAAAAAAAAAAAAAAAAAAAQIgMnH/2gAIAQEABj8CHYVWH//EABoQAQACAwEAAAAAAAAAAAAAAAEAMREhcdH/2gAIAQEAAT8hqeQqRasQ5s+ykxqUn//aAAwDAQACAAMAAAAQVN//xAAXEQEAAwAAAAAAAAAAAAAAAAAAAREx/9oACAEDAQE/EJ1b/8QAFxEBAAMAAAAAAAAAAAAAAAAAARARIf/aAAgBAgEBPxACjI//xAAeEAEBAAIBBQEAAAAAAAAAAAABEQAhMUFRcYGhsf/aAAgBAQABPxDeiujlE1ls0AHeYppLUHWF+5yeT8Mi2bmO7x9Z/9k='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"boston\"\n        title=\"\"\n        src=\"/static/celtics-a8b4b26290bb67fa2396fc6d3ae9d0cc-b80fa.jpg\"\n        srcset=\"/static/celtics-a8b4b26290bb67fa2396fc6d3ae9d0cc-cf410.jpg 163w,\n/static/celtics-a8b4b26290bb67fa2396fc6d3ae9d0cc-62f2a.jpg 325w,\n/static/celtics-a8b4b26290bb67fa2396fc6d3ae9d0cc-b80fa.jpg 650w,\n/static/celtics-a8b4b26290bb67fa2396fc6d3ae9d0cc-08cb4.jpg 975w,\n/static/celtics-a8b4b26290bb67fa2396fc6d3ae9d0cc-f2bf9.jpg 1300w,\n/static/celtics-a8b4b26290bb67fa2396fc6d3ae9d0cc-fd4ba.jpg 1950w,\n/static/celtics-a8b4b26290bb67fa2396fc6d3ae9d0cc-79e2c.jpg 2788w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>The Celtics played the Nets last night. Here's a picture of their subreddit, <a href=\"reddit.com/r/gonets\">reddit.com/r/gonets</a> after the game. I don't think I need to say who won the game.</p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/nets-4461f687df0293a67d3d536006070b1b-0c538.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 58.424507658643336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIFBP/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAbLqxOMof//EABsQAAEEAwAAAAAAAAAAAAAAAAIAAQMyEBQh/9oACAEBAAEFAm6io8cZYOmxIv/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABwQAAIBBQEAAAAAAAAAAAAAAAABcQIDEBExof/aAAgBAQAGPwIcG3a8eKoOn//EABsQAAICAwEAAAAAAAAAAAAAAAABESExQWGR/9oACAEBAAE/IcRu3YiW24glTVjw7o5/D//aAAwDAQACAAMAAAAQoA//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPxBX/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHxABAAICAQUBAAAAAAAAAAAAAREhAEExUWGBkbHR/9oACAEBAAE/EAiSpyzVz3D5hIwiw5msXCADo8ZKIm4vd4hjYx6cDA1dP5n/2Q=='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"nets\"\n        title=\"\"\n        src=\"/static/nets-4461f687df0293a67d3d536006070b1b-b80fa.jpg\"\n        srcset=\"/static/nets-4461f687df0293a67d3d536006070b1b-cf410.jpg 163w,\n/static/nets-4461f687df0293a67d3d536006070b1b-62f2a.jpg 325w,\n/static/nets-4461f687df0293a67d3d536006070b1b-b80fa.jpg 650w,\n/static/nets-4461f687df0293a67d3d536006070b1b-08cb4.jpg 975w,\n/static/nets-4461f687df0293a67d3d536006070b1b-f2bf9.jpg 1300w,\n/static/nets-4461f687df0293a67d3d536006070b1b-fd4ba.jpg 1950w,\n/static/nets-4461f687df0293a67d3d536006070b1b-0c538.jpg 2742w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>These two pictures exemplify my idea that you can tell who won a game by the feelings of fans on their teams subreddit.</p>\n<h3>Getting the Winners and Loser From the Day</h3>\n<p>Before doing anything else, we need to get the winners and losers. Since we're building our \"training set\", we want to keep each team labeled as a winner or a loser so we can find a pattern once we collect enough data. I looked into an API or two to get the games data, but I settled on scraping the data myself from basketball-reference.com because the APIs couldn't do exactly what I wanted. I hope to replace this code with an API since basketball-reference.com can change their website anytime.</p>\n<pre><code class=\"language-python\">def get_days_teams():\n    # get games of the day\n    from bs4 import BeautifulSoup, SoupStrainer, Comment\n    import requests\n\n    headers = {\n        \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9\",\n    }\n\n    now = datetime.datetime.now()\n\n    url = \"https://www.basketball-reference.com/boxscores/?month={0}&#x26;day={1}&#x26;year={2}\".format(now.month, now.day-1, now.year)\n\n    result = requests.get(url, headers=headers)\n    soup = BeautifulSoup(result.content, 'html.parser')\n    content = soup.findAll(class_=\"teams\")\n\n    winners = []\n    losers = []\n    for teams in content:\n        # find winner\n        winner = teams.find(class_=\"winner\")\n        for td in winner.find('td'):\n            winners.append(td.text)\n        loser = teams.find(class_=\"loser\")\n        for td in loser.find('td'):\n            losers.append(td.text)\n\n    return winners, losers\n</code></pre>\n<pre><code class=\"language-python\">> ['Boston', 'Detroit', 'Indiana', 'Golden State', 'Minnesota', 'Cleveland', 'Sacramento', 'Milwaukee']\n> ['Brooklyn', 'Houston', 'Chicago', 'LA Clippers', 'New Orleans', 'Orlando', 'Denver', 'Washington']\n</code></pre>\n<h3>Retrieving Subreddit Posts</h3>\n<p>Once we have the winners and losers, we can map those to their respective subreddit and grab the top posts from the day.</p>\n<pre><code class=\"language-python\">def get_posts(subreddit):\n    from bs4 import BeautifulSoup, SoupStrainer, Comment\n    import requests\n\n    headers = {\n        \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9\",\n    }\n\n    result = requests.get('https://www.reddit.com' + subreddit, headers=headers)\n    soup = BeautifulSoup(result.content, 'html.parser')\n    content = soup.findAll(class_=\"title\")\n\n    titles = content[2:-4:2] # need to cut out first two and last two, and remove repeating titles\n\n    sentences = [sen.text for sen in titles]\n    paragraph = ' '.join(w.strip() for w in [sen.text for sen in titles])\n    return paragraph, sentences\n</code></pre>\n<p>This code returns both each individual post, under sentences, and a full paragraph of each sentence joined together. It's still too early to decide what provides a better metric, so I'm using both.</p>\n<h3>Analyzing Sentiment</h3>\n<p>Now we can analyze the posts individually and the posts as a whole.</p>\n<pre><code class=\"language-python\">import nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n# nltk.download('vader_lexicon')\n# nltk.download('punkt')\n\ndef analyze_paragraph(paragraph):\n    sid = SentimentIntensityAnalyzer()\n    ss = sid.polarity_scores(paragraph)\n    return ss['pos'], ss['neu'], ss['neg'], ss['compound']\n\ndef analyze_sentences(sentences):\n    sid = SentimentIntensityAnalyzer()\n    pos, neu, neg, com = 0\n    for sentence in sentences:\n        ss = sid.polarity_scores(sentence)\n        pos += ss['pos']\n        neu += ss['neu']\n        neg += ss['neg']\n        com += ss['compound']\n    return pos, neu, neg, com\n</code></pre>\n<p>NLTK, or Natural Language Toolkit, has a package that can analyze the sentiment of text. Running polarity_scores on some text gives four scores.</p>\n<pre><code class=\"language-python\">> pos: 0.876, neu: 0.124, neg: 0.0, compound: 0.7925\n</code></pre>\n<p>Positive, neutral, and negative are all sentiment measures. Compound is what tells the intensity of positivity and negativity and is bounded between -1 and 1. When compound is close to 1, the text is super positive, and when it's close to -1, it's super negative. Here's a great, very in depth stack overflow post explaining exactly how the compound measure works. I intend to use the compound score, but I'm going to keep all the other scores as well. Space isn't an issue, so no sense in throwing it away before I make my prediction model.</p>\n<p>analyze paragraph takes in the full text joined together for each subreddit and returns the single compound score. analyze sentences takes in the list of posts and calculates the sum of compound scores. Each team has the same number of posts, so we don't need to worry about normalizing right now. Perhaps we'll need to once we start creating a model with more data, but it's good right now.</p>\n<h3>Getting Results</h3>\n<p>Finally, we can put all these pieces together and find the scores for each team.</p>\n<pre><code class=\"language-python\">def compute_all():\n    winners, losers = get_days_teams()\n    winner_data = compute_winners(winners)\n    loser_data = compute_losers(losers)\n    data = winner_data + loser_data\n    return data\n\ndef compute_winners(winners):\n    data = []\n    for team in winners:\n        paragraph, sentences = get_posts(subreddits[team])\n        sen_pos, sen_neu, sen_neg, sen_com = analyze_sentences(sentences)\n        par_pos, par_neu, par_neg, par_com = analyze_paragraph(paragraph)\n        data.append([team, sen_pos, sen_neu, sen_neg, sen_com, par_pos, par_neu, par_neg, par_com, True])\n    return data\n\ndef compute_losers(losers):\n    data = []\n    for team in losers:\n        paragraph, sentences = get_posts(subreddits[team])\n        sen_pos, sen_neu, sen_neg, sen_com = analyze_sentences(sentences)\n        par_pos, par_neu, par_neg, par_com = analyze_paragraph(paragraph)\n        data.append([team, sen_pos, sen_neu, sen_neg, sen_com, par_pos, par_neu, par_neg, par_com, False])\n    return data\n</code></pre>\n<p>Note the format of the output for each team. I'm storing each game for each team as a row with the team name, the post score, the total score, and a boolean variable indicating if they won or lost. This allows me to export the data very simply to a csv and interact with it with Pandas in the future or analysis. I've found it's extremely important to really think about how you want to store your data and what data you want to store. If space is not an issue, it's better to just have more data because you can't go back and get the data ¯\\_(ツ)_/¯</p>\n<h3>Storing for Later Use</h3>\n<p>Now we can store the data in pandas, view the results, and append to an existing csv file.</p>\n<pre><code class=\"language-python\"># store results\nimport pandas as pd\nimport datetime\nimport os\n\ndata = compute_all()\ndf = pd.DataFrame(data, columns=['team', 'sen_pos', 'sen_neu', 'sen_neg', 'sen_com', 'par_pos', 'par_neu', 'par_neg', 'par_com', 'won'])\ndf['date'] = pd.to_datetime(datetime.datetime.now())\ndf.index = df['date']\ndel df['date']\nwith open('nba_sentiment.csv', 'a') as f:\n    df.to_csv(f, index=False, mode='a', header=(not os.path.exists(f)))\n</code></pre>\n<p>Which gives the results</p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>date</th>\n<th>team</th>\n<th>sen_pos</th>\n<th>sen_neu</th>\n<th>sen_neg</th>\n<th>sen_com</th>\n<th>par_pos</th>\n<th>par_neu</th>\n<th>par_neg</th>\n<th>par_com</th>\n<th>won</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2018-01-07</td>\n<td>Boston</td>\n<td>1.508</td>\n<td>24.014</td>\n<td>1.478</td>\n<td>1.0604</td>\n<td>0.080</td>\n<td>0.874</td>\n<td>0.046</td>\n<td>0.9163</td>\n<td>True</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Detroit</td>\n<td>0.638</td>\n<td>25.185</td>\n<td>0.177</td>\n<td>1.2514</td>\n<td>0.054</td>\n<td>0.931</td>\n<td>0.015</td>\n<td>0.8574</td>\n<td>True</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Indiana</td>\n<td>3.831</td>\n<td>21.794</td>\n<td>1.375</td>\n<td>4.4474</td>\n<td>0.113</td>\n<td>0.844</td>\n<td>0.043</td>\n<td>0.9365</td>\n<td>True</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Golden State</td>\n<td>2.746</td>\n<td>23.576</td>\n<td>0.677</td>\n<td>4.3177</td>\n<td>0.131</td>\n<td>0.836</td>\n<td>0.033</td>\n<td>0.9906</td>\n<td>True</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Minnesota</td>\n<td>2.113</td>\n<td>22.509</td>\n<td>1.378</td>\n<td>1.6908</td>\n<td>0.091</td>\n<td>0.862</td>\n<td>0.047</td>\n<td>0.9365</td>\n<td>True</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Cleveland</td>\n<td>2.913</td>\n<td>23.112</td>\n<td>0.975</td>\n<td>3.8053</td>\n<td>0.141</td>\n<td>0.821</td>\n<td>0.037</td>\n<td>0.9888</td>\n<td>True</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Sacramento</td>\n<td>2.314</td>\n<td>21.636</td>\n<td>1.050</td>\n<td>1.9895</td>\n<td>0.096</td>\n<td>0.865</td>\n<td>0.039</td>\n<td>0.9307</td>\n<td>True</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Milwaukee</td>\n<td>2.728</td>\n<td>21.862</td>\n<td>2.410</td>\n<td>0.5261</td>\n<td>0.112</td>\n<td>0.786</td>\n<td>0.102</td>\n<td>0.7825</td>\n<td>True</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Brooklyn</td>\n<td>2.462</td>\n<td>20.851</td>\n<td>2.687</td>\n<td>0.1842</td>\n<td>0.094</td>\n<td>0.822</td>\n<td>0.084</td>\n<td>0.6326</td>\n<td>False</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Houston</td>\n<td>1.780</td>\n<td>22.713</td>\n<td>1.507</td>\n<td>0.0988</td>\n<td>0.091</td>\n<td>0.847</td>\n<td>0.062</td>\n<td>0.9347</td>\n<td>False</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Chicago</td>\n<td>2.207</td>\n<td>22.777</td>\n<td>1.016</td>\n<td>4.1347</td>\n<td>0.097</td>\n<td>0.867</td>\n<td>0.035</td>\n<td>0.9806</td>\n<td>False</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>LA Clippers</td>\n<td>1.214</td>\n<td>24.353</td>\n<td>1.433</td>\n<td>0.8443</td>\n<td>0.050</td>\n<td>0.914</td>\n<td>0.036</td>\n<td>0.5914</td>\n<td>False</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>New Orleans</td>\n<td>2.023</td>\n<td>20.676</td>\n<td>2.301</td>\n<td>-0.0109</td>\n<td>0.083</td>\n<td>0.853</td>\n<td>0.064</td>\n<td>0.5754</td>\n<td>False</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Orlando</td>\n<td>1.822</td>\n<td>23.606</td>\n<td>0.572</td>\n<td>1.7442</td>\n<td>0.093</td>\n<td>0.888</td>\n<td>0.019</td>\n<td>0.9718</td>\n<td>False</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Denver</td>\n<td>1.724</td>\n<td>23.939</td>\n<td>1.337</td>\n<td>1.1355</td>\n<td>0.085</td>\n<td>0.866</td>\n<td>0.049</td>\n<td>0.9214</td>\n<td>False</td>\n</tr>\n<tr>\n<td>2018-01-07</td>\n<td>Washington</td>\n<td>2.808</td>\n<td>21.159</td>\n<td>2.033</td>\n<td>1.9738</td>\n<td>0.129</td>\n<td>0.787</td>\n<td>0.083</td>\n<td>0.9325</td>\n<td>False</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3>Future Plans for Pt. 2</h3>\n<p>With the pipeline all setup, I just have to run this code every night after the day's game to start building up this dataset. The next steps are to analyze what sentiment is correlated to a win. Thanks for reading and stay tuned for pt. 2!</p>",frontmatter:{path:"/nba-subreddit-sentiment",title:"Predicting Daily NBA Winners by Subreddit Sentiment Pt. 1",subtitle:"",date:"2018-01-04T00:15:29-06:00",indexImage:{childImageSharp:{resolutions:{width:1191,height:794,src:"/static/crying-b21190e1f4808613b093dfe234799776-98f17.jpg",srcSet:"/static/crying-b21190e1f4808613b093dfe234799776-98f17.jpg 1x"}}}}}},pathContext:{}}}});
//# sourceMappingURL=path---nba-subreddit-sentiment-aed0219881944c5386ad.js.map